/**
 * üö® ALERTING HANDLER - Alertes intelligentes
 * 
 * Handler d√©di√© aux alertes business et techniques :
 * - Alertes sur taux d'√©chec √©lev√©
 * - D√©tection d'anomalies (pics, chutes)
 * - Alertes de co√ªt (d√©passement budget)
 * - Int√©gration avec les syst√®mes existants (logs, m√©triques)
 */

import { EventHandler, NotificationCreatedEvent, NotificationSentEvent, NotificationFailedEvent } from '../modern.event.bus';
import { ProductionLogger } from '../../logging/logger.production';

interface AlertingStats {
  failuresByChannel: Record<string, { count: number; lastHour: Date[] }>;
  costsByChannel: Record<string, { total: number; lastHour: number[] }>;
  volumeByChannel: Record<string, { count: number; lastHour: Date[] }>;
  lastReset: Date;
}

export class AlertingHandler implements EventHandler<any> {
  name = 'intelligent-alerting';
  priority = 3; // Important mais pas critique
  timeout = 2000;
  
  private logger: ProductionLogger;
  private stats: AlertingStats;
  private alertThresholds = {
    failureRate: 20, // 20% d'√©checs
    costPerHour: 10, // 10‚Ç¨ par heure
    volumeSpike: 200, // 200% d'augmentation
    consecutiveFailures: 5 // 5 √©checs cons√©cutifs
  };
  
  constructor() {
    this.logger = new ProductionLogger({ level: 'warn', enableConsole: true });
    this.stats = {
      failuresByChannel: {},
      costsByChannel: {},
      volumeByChannel: {},
      lastReset: new Date()
    };
    
    // Reset des stats horaires
    setInterval(() => {
      this.resetHourlyStats();
    }, 60 * 60 * 1000); // Chaque heure
  }
  
  async handle(event: NotificationCreatedEvent | NotificationSentEvent | NotificationFailedEvent): Promise<void> {
    try {
      const channel = event.channel;
      
      // Mise √† jour des stats
      this.updateStats(event);
      
      // V√©rification des alertes selon le type d'√©v√©nement
      if ('deliveryTime' in event) {
        // NotificationSentEvent
        await this.checkCostAlerts(channel, event as NotificationSentEvent);
      } else if ('error' in event) {
        // NotificationFailedEvent
        await this.checkFailureAlerts(channel, event as NotificationFailedEvent);
      } else if ('templateId' in event) {
        // NotificationCreatedEvent
        await this.checkVolumeAlerts(channel, event as NotificationCreatedEvent);
      }
      
    } catch (error) {
      // Alerting handler ne doit jamais faire √©chouer le flux
      console.error('AlertingHandler error:', error);
    }
  }
  
  /**
   * Mise √† jour des statistiques internes
   */
  private updateStats(event: any): void {
    const channel = event.channel;
    const now = new Date();
    
    // Initialiser les stats du canal si n√©cessaire
    if (!this.stats.failuresByChannel[channel]) {
      this.stats.failuresByChannel[channel] = { count: 0, lastHour: [] };
      this.stats.costsByChannel[channel] = { total: 0, lastHour: [] };
      this.stats.volumeByChannel[channel] = { count: 0, lastHour: [] };
    }
    
    if ('error' in event) {
      // √âchec
      this.stats.failuresByChannel[channel].count++;
      this.stats.failuresByChannel[channel].lastHour.push(now);
    } else if ('deliveryTime' in event && event.cost) {
      // Succ√®s avec co√ªt
      this.stats.costsByChannel[channel].total += event.cost;
      this.stats.costsByChannel[channel].lastHour.push(event.cost);
    } else if ('templateId' in event) {
      // Cr√©ation
      this.stats.volumeByChannel[channel].count++;
      this.stats.volumeByChannel[channel].lastHour.push(now);
    }
  }
  
  /**
   * Alertes sur les √©checs
   */
  private async checkFailureAlerts(channel: string, event: NotificationFailedEvent): Promise<void> {
    const channelStats = this.stats.failuresByChannel[channel];
    const totalVolume = this.stats.volumeByChannel[channel]?.count || 0;
    
    // Taux d'√©chec √©lev√©
    if (totalVolume > 10) { // Au moins 10 notifications pour √™tre significatif
      const failureRate = (channelStats.count / totalVolume) * 100;
      if (failureRate >= this.alertThresholds.failureRate) {
        await this.sendAlert('HIGH_FAILURE_RATE', {
          channel,
          failureRate: `${failureRate.toFixed(1)}%`,
          totalFailures: channelStats.count,
          totalVolume,
          lastError: event.error
        });
      }
    }
    
    // √âchecs cons√©cutifs dans la derni√®re heure
    const lastHourFailures = this.getLastHourCount(channelStats.lastHour);
    if (lastHourFailures >= this.alertThresholds.consecutiveFailures) {
      await this.sendAlert('CONSECUTIVE_FAILURES', {
        channel,
        consecutiveFailures: lastHourFailures,
        error: event.error,
        canRetry: event.canRetry
      });
    }
    
    // Erreurs critiques sp√©cifiques
    if (this.isCriticalError(event.error)) {
      await this.sendAlert('CRITICAL_ERROR', {
        channel,
        error: event.error,
        notificationId: event.notificationId,
        recipientId: event.recipientId
      });
    }
  }
  
  /**
   * Alertes sur les co√ªts
   */
  private async checkCostAlerts(channel: string, event: NotificationSentEvent): Promise<void> {
    const channelStats = this.stats.costsByChannel[channel];
    
    // Co√ªt horaire d√©pass√©
    const lastHourCost = channelStats.lastHour.reduce((sum, cost) => sum + cost, 0);
    if (lastHourCost >= this.alertThresholds.costPerHour) {
      await this.sendAlert('HIGH_COST', {
        channel,
        hourlyCoset: `${lastHourCost.toFixed(2)}‚Ç¨`,
        threshold: `${this.alertThresholds.costPerHour}‚Ç¨`,
        totalCost: `${channelStats.total.toFixed(2)}‚Ç¨`
      });
    }
    
    // Co√ªt unitaire anormalement √©lev√©
    const averageCost = channelStats.total / channelStats.lastHour.length;
    if (event.cost && event.cost > averageCost * 3) { // 3x la moyenne
      await this.sendAlert('UNUSUAL_COST', {
        channel,
        unitCost: `${event.cost.toFixed(3)}‚Ç¨`,
        averageCost: `${averageCost.toFixed(3)}‚Ç¨`,
        notificationId: event.notificationId
      });
    }
  }
  
  /**
   * Alertes sur le volume
   */
  private async checkVolumeAlerts(channel: string, event: NotificationCreatedEvent): Promise<void> {
    const channelStats = this.stats.volumeByChannel[channel];
    
    // Pic de volume (spike detection)
    const lastHourVolume = this.getLastHourCount(channelStats.lastHour);
    const previousHourVolume = this.getPreviousHourCount(channelStats.lastHour);
    
    if (previousHourVolume > 0) {
      const spikePercent = ((lastHourVolume - previousHourVolume) / previousHourVolume) * 100;
      if (spikePercent >= this.alertThresholds.volumeSpike) {
        await this.sendAlert('VOLUME_SPIKE', {
          channel,
          spikePercent: `${spikePercent.toFixed(0)}%`,
          currentHourVolume: lastHourVolume,
          previousHourVolume,
          priority: event.priority
        });
      }
    }
  }
  
  /**
   * Envoyer une alerte (utilise le syst√®me de logging existant)
   */
  private async sendAlert(alertType: string, data: Record<string, any>): Promise<void> {
    const alertMessage = `üö® ALERT: ${alertType}`;
    
    // Log d'alerte structur√© (sera captur√© par les syst√®mes de monitoring)
    this.logger.error(alertMessage, {
      alertType,
      severity: this.getAlertSeverity(alertType),
      timestamp: new Date().toISOString(),
      ...data
    });
    
    // Dans une version avanc√©e, on pourrait envoyer vers :
    // - Slack/Teams webhook
    // - PagerDuty
    // - Email aux admins
    // - Push notification mobile
    
    console.warn(`${alertMessage}:`, data);
  }
  
  /**
   * D√©terminer la s√©v√©rit√© d'une alerte
   */
  private getAlertSeverity(alertType: string): 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL' {
    switch (alertType) {
      case 'CRITICAL_ERROR':
        return 'CRITICAL';
      case 'HIGH_FAILURE_RATE':
      case 'CONSECUTIVE_FAILURES':
        return 'HIGH';
      case 'HIGH_COST':
      case 'VOLUME_SPIKE':
        return 'MEDIUM';
      default:
        return 'LOW';
    }
  }
  
  /**
   * V√©rifier si une erreur est critique
   */
  private isCriticalError(error: string): boolean {
    const criticalPatterns = [
      'quota exceeded',
      'account suspended',
      'billing error',
      'api key invalid',
      'service unavailable'
    ];
    
    return criticalPatterns.some(pattern => 
      error.toLowerCase().includes(pattern)
    );
  }
  
  /**
   * Compter les √©v√©nements de la derni√®re heure
   */
  private getLastHourCount(timestamps: Date[]): number {
    const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);
    return timestamps.filter(ts => ts > oneHourAgo).length;
  }
  
  /**
   * Compter les √©v√©nements de l'heure pr√©c√©dente
   */
  private getPreviousHourCount(timestamps: Date[]): number {
    const twoHoursAgo = new Date(Date.now() - 2 * 60 * 60 * 1000);
    const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);
    return timestamps.filter(ts => ts > twoHoursAgo && ts <= oneHourAgo).length;
  }
  
  /**
   * Reset des statistiques horaires
   */
  private resetHourlyStats(): void {
    const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);
    
    Object.values(this.stats.failuresByChannel).forEach(stat => {
      stat.lastHour = stat.lastHour.filter(ts => ts > oneHourAgo);
    });
    
    Object.values(this.stats.volumeByChannel).forEach(stat => {
      stat.lastHour = stat.lastHour.filter(ts => ts > oneHourAgo);
    });
    
    // Reset des co√ªts horaires (on garde seulement les co√ªts de la derni√®re heure)
    Object.values(this.stats.costsByChannel).forEach(stat => {
      stat.lastHour = stat.lastHour.slice(-60); // Garder max 60 entries
    });
    
    this.stats.lastReset = new Date();
    
    this.logger.debug('üîÑ Hourly alerting stats reset completed');
  }
}